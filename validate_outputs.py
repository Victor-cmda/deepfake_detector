"""
Script para validar que todos os outputs necess√°rios para o TCC foram gerados corretamente.
"""

from pathlib import Path
import pandas as pd

def validate_outputs():
    """Valida todos os outputs necess√°rios conforme instructions.json"""
    
    print("\n" + "="*70)
    print("VALIDA√á√ÉO DE OUTPUTS PARA O TCC")
    print("="*70 + "\n")
    
    all_ok = True
    
    # Outputs esperados conforme instructions.json
    expected_outputs = {
        'models/model_best.pt': 'Modelo treinado',
        'outputs/metrics_train.csv': 'M√©tricas de treino',
        'outputs/metrics_cross.csv': 'M√©tricas cross-dataset',
        'outputs/figures/training_curves.png': 'Curvas de treinamento',
        'outputs/figures/f1_by_dataset.png': 'F1 por dataset',
        'outputs/figures/confusion_matrix.png': 'Matriz de confus√£o',
        'outputs/figures/gradcam_examples.png': 'Exemplos Grad-CAM',
        'outputs/reports/interface_log.csv': 'Log da interface',
        'outputs/reports/run_report.md': 'Relat√≥rio t√©cnico',
        'outputs/reports/table_metrics.csv': 'Tabela de m√©tricas',
        'outputs/reports/robustness.csv': 'Teste de robustez',
    }
    
    print("üìã Verificando arquivos obrigat√≥rios:\n")
    
    for file_path, description in expected_outputs.items():
        path = Path(file_path)
        if path.exists():
            size = path.stat().st_size
            if size > 0:
                size_str = f"{size / 1024:.1f} KB" if size < 1024*1024 else f"{size / (1024*1024):.1f} MB"
                print(f"  ‚úÖ {description:30s} - {file_path} ({size_str})")
            else:
                print(f"  ‚ö†Ô∏è  {description:30s} - {file_path} (VAZIO!)")
                all_ok = False
        else:
            print(f"  ‚ùå {description:30s} - {file_path} (N√ÉO ENCONTRADO)")
            all_ok = False
    
    print("\n" + "-"*70 + "\n")
    
    # Validar conte√∫do das m√©tricas
    print("üìä Validando conte√∫do das m√©tricas:\n")
    
    # M√©tricas de treino
    if Path('outputs/metrics_train.csv').exists():
        df_train = pd.read_csv('outputs/metrics_train.csv')
        print(f"  ‚úÖ metrics_train.csv: {len(df_train)} √©pocas")
        print(f"     - Melhor Val AUC: {df_train['val_auc'].max():.4f} (√©poca {df_train['val_auc'].idxmax() + 1})")
        print(f"     - Melhor Val F1: {df_train['val_f1'].max():.4f} (√©poca {df_train['val_f1'].idxmax() + 1})")
        print(f"     - Train Loss final: {df_train.iloc[-1]['train_loss']:.4f}")
    else:
        print("  ‚ùå metrics_train.csv n√£o encontrado")
        all_ok = False
    
    # M√©tricas cross-dataset
    if Path('outputs/metrics_cross.csv').exists():
        df_cross = pd.read_csv('outputs/metrics_cross.csv')
        df_cross_valid = df_cross[df_cross['total_samples'] > 100]
        print(f"\n  ‚úÖ metrics_cross.csv: {len(df_cross_valid)} datasets v√°lidos")
        for _, row in df_cross_valid.iterrows():
            print(f"     - {row['dataset']}: AUC {row['auc']:.4f}, F1 {row['f1']:.4f} ({int(row['total_samples'])} amostras)")
    else:
        print("  ‚ùå metrics_cross.csv n√£o encontrado")
        all_ok = False
    
    # Tabela de m√©tricas
    if Path('outputs/reports/table_metrics.csv').exists():
        df_metrics = pd.read_csv('outputs/reports/table_metrics.csv')
        print(f"\n  ‚úÖ table_metrics.csv: {len(df_metrics)} m√©tricas consolidadas")
    else:
        print("  ‚ùå table_metrics.csv n√£o encontrado")
        all_ok = False
    
    print("\n" + "-"*70 + "\n")
    
    # Verificar heatmaps
    heatmaps_dir = Path('outputs/heatmaps')
    if heatmaps_dir.exists():
        heatmaps = list(heatmaps_dir.glob('*.png'))
        print(f"üì∏ Heatmaps Grad-CAM: {len(heatmaps)} exemplos mantidos\n")
    else:
        print("‚ö†Ô∏è  Diret√≥rio heatmaps n√£o encontrado\n")
    
    print("="*70)
    
    if all_ok:
        print("‚úÖ VALIDA√á√ÉO COMPLETA: TODOS OS OUTPUTS EST√ÉO OK!")
        print("="*70)
        print("\nüéì Arquivos prontos para uso no TCC:")
        print("\nüìä FIGURAS (outputs/figures/):")
        print("   1. training_curves.png - Curvas de treinamento")
        print("   2. f1_by_dataset.png - Compara√ß√£o F1/AUC")
        print("   3. confusion_matrix.png - Matrizes de confus√£o")
        print("   4. gradcam_examples.png - Mapas de aten√ß√£o")
        print("\nüìÑ RELAT√ìRIOS (outputs/reports/):")
        print("   1. table_metrics.csv - M√©tricas consolidadas")
        print("   2. run_report.md - Relat√≥rio t√©cnico completo")
        print("\nüìà M√âTRICAS BRUTAS:")
        print("   1. outputs/metrics_train.csv - Hist√≥rico de treino")
        print("   2. outputs/metrics_cross.csv - Cross-dataset evaluation")
        print("\nüìö DOCUMENTA√á√ÉO:")
        print("   - OUTPUTS_TCC_REFERENCIA.md - Guia completo com textos")
        print("\n")
    else:
        print("‚ùå VALIDA√á√ÉO FALHOU: Alguns outputs est√£o faltando!")
        print("="*70)
        print("\nExecute novamente o script de regenera√ß√£o:")
        print("  python clean_and_regenerate.py")
        print("\n")
    
    return all_ok


if __name__ == "__main__":
    import sys
    success = validate_outputs()
    sys.exit(0 if success else 1)
