TAREFA 15: Documentação final e instruções de uso
==================================================
Data: 28/10/2025
Status: CONCLUÍDA

Ações Realizadas:
-----------------
1. ✓ Editado README.md com documentação completa
2. ✓ Instruções de instalação detalhadas
3. ✓ Comandos exatos de treino e avaliação
4. ✓ Instruções de uso da interface Gradio
5. ✓ Lista completa de arquivos finais
6. ✓ Comandos úteis e troubleshooting

Conteúdo do README.md:
----------------------

SEÇÕES CRIADAS (11):

1. ESPECIFICAÇÕES TÉCNICAS
   - Python 3.11.5
   - PyTorch >= 2.2
   - Arquitetura: ResNet-34 + BiLSTM (256x2)
   - Datasets: FaceForensics++, Celeb-DF-v2, WildDeepfake
   - Explicabilidade: Grad-CAM
   - Interface: Gradio

2. ESTRUTURA DO PROJETO
   - Árvore completa de diretórios
   - Descrição de cada pasta
   - Lista de todos os arquivos finais
   - Organização dos outputs:
     * figures/ (13 arquivos PNG)
     * heatmaps/ (vídeos Grad-CAM)
     * logs/ (22 arquivos de log)
     * reports/ (4 arquivos CSV/MD)
   - Métricas: metrics_train.csv, metrics_cross.csv
   - Modelo: model_best.pt

3. INSTALAÇÃO
   
   Passo 1: Clonar repositório
   ```bash
   git clone <repository-url>
   cd deepfake_detector
   ```
   
   Passo 2: Configurar Python 3.11.5
   
   Opção A - pyenv (recomendado):
   ```bash
   curl https://pyenv.run | bash
   pyenv install 3.11.5
   pyenv local 3.11.5
   python --version  # Verificar: Python 3.11.5
   ```
   
   Opção B - conda:
   ```bash
   conda create -n deepfake python=3.11.5
   conda activate deepfake
   ```
   
   Passo 3: Instalar dependências
   ```bash
   pip install -r requirements.txt
   ```
   
   Dependências principais listadas:
   - torch>=2.2.0
   - torchvision>=0.17.0
   - facenet-pytorch (MTCNN)
   - opencv-python
   - gradio
   - matplotlib, seaborn
   - pandas, numpy
   - scikit-learn
   - tqdm
   
   Passo 4: Organizar datasets
   - Estrutura esperada documentada
   - Comandos para gerar índices CSV
   - Comando para criar splits (70/15/15)

4. TREINAMENTO
   
   Comando principal:
   ```bash
   python src/train.py
   ```
   
   Configurações detalhadas:
   - Otimizador: Adam (lr=1e-4, weight_decay=1e-5)
   - Loss: Binary Cross-Entropy (BCE)
   - Scheduler: ReduceLROnPlateau (patience=3, factor=0.5)
   - Early Stopping: Patience=5 épocas
   - Batch Size: 4 (ajustável)
   - Frames por vídeo: 16
   - Epochs: Até convergência
   
   Outputs gerados:
   - models/model_best.pt
   - outputs/metrics_train.csv
   - outputs/logs/early_stopping.txt
   - outputs/figures/training_curves.png
   
   Exemplo de execução:
   ```
   Epoch 1/100
   Train Loss: 0.4234, Val Loss: 0.3156, Val F1: 0.8923
   Melhor modelo salvo!
   
   Epoch 2/100
   Train Loss: 0.2891, Val Loss: 0.0234, Val F1: 1.0000
   Melhor modelo salvo!
   
   Early stopping acionado na época 7
   Melhor Val F1: 1.0000 (época 2)
   ```
   
   Métricas de treinamento documentadas:
   - epoch, train_loss, val_loss
   - val_accuracy, val_precision, val_recall
   - val_f1, val_auc, learning_rate

5. AVALIAÇÃO
   
   5.1 Avaliação Cross-Dataset:
   ```bash
   python src/evaluate.py
   ```
   
   Datasets avaliados:
   1. FaceForensics++ (test split)
   2. Celeb-DF-v2 (completo)
   3. WildDeepfake (completo)
   
   Outputs:
   - outputs/metrics_cross.csv
   - outputs/figures/confusion_matrix_*.png (3)
   - outputs/figures/roc_curve_*.png (3)
   - outputs/figures/f1_by_dataset.png
   - outputs/reports/table_metrics.csv
   
   Métricas:
   - Accuracy, Precision, Recall, F1-Score, AUC-ROC
   - Confusion Matrix
   - TP, FP, TN, FN
   
   5.2 Gerar Grad-CAM:
   ```bash
   python src/gradcam.py
   ```
   
   Configurações:
   - Layer alvo: model.resnet.layer4
   - Frames por vídeo: 8 (igualmente espaçados)
   - Output: outputs/heatmaps/
   
   Exemplo programático fornecido:
   ```python
   from src.gradcam import generate_gradcam
   heatmaps = generate_gradcam(
       model_path='models/model_best.pt',
       video_path='data/celebdf/videos_fake/video_001.mp4',
       output_dir='outputs/heatmaps/',
       num_frames=8
   )
   ```
   
   Outputs:
   - outputs/heatmaps/<video_name>_gradcam.mp4
   - outputs/figures/gradcam_examples.png
   
   5.3 Teste de Robustez:
   ```bash
   python src/evaluate.py  # Incluído automaticamente
   ```
   
   Degradações testadas (13):
   1. Original (baseline)
   2. Ruído Gaussiano: σ ∈ {0.01, 0.05, 0.10}
   3. Blur Gaussiano: kernel ∈ {3, 7, 15}
   4. Compressão JPEG: quality ∈ {90, 50, 20}
   5. Redimensionamento: scale ∈ {75%, 50%, 25%}
   
   Outputs:
   - outputs/reports/robustness.csv
   - outputs/figures/robustness.png
   
   Métricas:
   - delta_probabilidade
   - Estatísticas: média, máx, mín, std
   
   Resultados esperados:
   - Degradação mais impactante: Blur k=15 (Δ=0.0274)
   - Δ médio: 0.0110 (1.1%)
   - Modelo MUITO ROBUSTO

6. INTERFACE GRADIO
   
   Comando:
   ```bash
   python src/interface.py
   ```
   
   URL local: http://127.0.0.1:7860
   
   Funcionalidades:
   - Upload de vídeo (.mp4, .avi, .mov)
   - Detecção automática de deepfake
   - Visualização Grad-CAM
   - Probabilidade de fake (0-100%)
   - Log em outputs/reports/interface_log.csv
   
   Uso programático:
   ```python
   from src.interface import predict
   result = predict('data/celebdf/videos_fake/video_001.mp4')
   print(f"Probabilidade Fake: {result['probability']:.2%}")
   print(f"Label: {result['label']}")
   print(f"Tempo: {result['inference_time']:.2f}s")
   ```
   
   Interface log documenta:
   - timestamp
   - video_path
   - probabilidade_fake
   - label (REAL ou FAKE)
   - tempo_inferencia

7. RELATÓRIOS
   
   7.1 Relatório Técnico Completo:
   ```bash
   python -c "from src.utils import generate_technical_report; generate_technical_report()"
   ```
   
   Output: outputs/reports/run_report.md
   
   Seções (8):
   1. Informações do Sistema
   2. Configurações do Modelo
   3. Métricas de Treinamento
   4. Métricas Cross-Dataset
   5. Análise de Robustez
   6. Grad-CAM e Explicabilidade
   7. Logs de Interface
   8. Arquivos Gerados
   
   7.2 Gerar Todas as Figuras:
   ```bash
   python -c "from src.evaluate import generate_all_figures_and_reports; generate_all_figures_and_reports()"
   ```
   
   Figuras:
   - training_curves.png (4200x1500px, 300 DPI)
   - f1_by_dataset.png (3000x1800px, 300 DPI)
   - gradcam_examples.png (2250x1500px, 150 DPI)

8. ARQUIVOS FINAIS
   
   8.1 Modelos:
   - models/model_best.pt (93.4 MB)
   
   8.2 Métricas:
   - outputs/metrics_train.csv
   - outputs/metrics_cross.csv
   - outputs/reports/table_metrics.csv
   - outputs/reports/robustness.csv
   - outputs/reports/interface_log.csv
   
   8.3 Figuras (13):
   - training_curves.png
   - f1_by_dataset.png
   - gradcam_examples.png
   - robustness.png
   - confusion_matrix_*.png (3)
   - roc_curve_*.png (3)
   - model_architecture.png
   - preprocessing_*.png (2)
   
   8.4 Relatórios:
   - outputs/reports/run_report.md
   
   8.5 Logs (22 arquivos):
   - early_stopping.txt
   - preprocessing_stats.txt
   - model_specs.txt
   - dataloader_stats.txt
   - step_*.txt (1-15)
   - README_tasks_7_8.md
   - validation_*.txt (2)

9. COMANDOS ÚTEIS
   
   9.1 Pipeline Completo (7 passos):
   ```bash
   # 1. Criar índices dos datasets
   python -c "from src.preprocessing import create_dataset_index; \
   create_dataset_index('data/faceforensicspp', 'data/faceforensicspp_index.csv'); \
   create_dataset_index('data/celebdf', 'data/celebdf_index.csv'); \
   create_dataset_index('data/wilddeepfake', 'data/wilddeepfake_index.csv')"
   
   # 2. Criar divisão treino/val/teste
   python -c "from src.preprocessing import create_train_val_test_split; \
   create_train_val_test_split('data/faceforensicspp_index.csv', 'data/splits_faceforensicspp.csv')"
   
   # 3. Treinar modelo
   python src/train.py
   
   # 4. Avaliar modelo (cross-dataset + robustez)
   python src/evaluate.py
   
   # 5. Gerar figuras e relatórios
   python -c "from src.evaluate import generate_all_figures_and_reports; generate_all_figures_and_reports()"
   
   # 6. Gerar relatório técnico
   python -c "from src.utils import generate_technical_report; generate_technical_report()"
   
   # 7. Iniciar interface Gradio
   python src/interface.py
   ```
   
   9.2 Verificar Estrutura:
   ```bash
   # Listar arquivos gerados
   ls -lh models/
   ls -lh outputs/metrics_*.csv
   ls -lh outputs/figures/
   ls -lh outputs/reports/
   ls -lh outputs/logs/
   
   # Verificar modelo treinado
   python -c "import torch; ckpt = torch.load('models/model_best.pt', map_location='cpu'); \
   print(f'Epoch: {ckpt[\"epoch\"]}'); print(f'Val F1: {ckpt[\"val_f1\"]:.4f}')"
   
   # Ver métricas
   head -10 outputs/metrics_train.csv
   cat outputs/metrics_cross.csv
   ```
   
   9.3 Predição em Lote:
   ```python
   import os
   from src.interface import predict
   from pathlib import Path
   
   video_dir = 'data/celebdf/videos_fake'
   for video_file in Path(video_dir).glob('*.mp4'):
       result = predict(str(video_file))
       print(f'{video_file.name}: {result["probability"]:.2%} ({result["label"]})')
   ```
   
   9.4 Visualizar Grad-CAM Específico:
   ```python
   from src.gradcam import generate_gradcam
   
   generate_gradcam(
       model_path='models/model_best.pt',
       video_path='data/celebdf/videos_fake/video_001.mp4',
       output_dir='outputs/heatmaps/',
       num_frames=8
   )
   ```

10. RESULTADOS ESPERADOS
    
    10.1 Métricas de Treinamento:
    - Val F1-Score: 1.0000 (época 2)
    - Val AUC-ROC: ~0.99+
    - Early Stopping: Acionado em ~7 épocas
    - Tempo por época: ~5-10 min (GPU) ou ~30-60 min (CPU)
    
    10.2 Métricas Cross-Dataset:
    
    Tabela comparativa:
    | Dataset          | Accuracy | Precision | Recall | F1-Score | AUC   |
    |------------------|----------|-----------|--------|----------|-------|
    | FaceForensics++  | ~0.98+   | ~0.95+    | ~0.95+ | ~0.95+   | ~0.99 |
    | Celeb-DF-v2      | ~0.85+   | ~0.80+    | ~0.85+ | ~0.82+   | ~0.90 |
    | WildDeepfake     | ~0.75+   | ~0.70+    | ~0.75+ | ~0.72+   | ~0.85 |
    
    10.3 Robustez:
    - Δ probabilidade médio: 0.0110 (1.1%)
    - Degradação mais impactante: Blur k=15 (Δ=0.027)
    - Classificação: MUITO ROBUSTO

11. TROUBLESHOOTING
    
    11.1 CUDA out of memory:
    Solução: Reduzir batch size em src/train.py
    ```python
    # Linha: batch_size = 4  →  batch_size = 2 ou 1
    ```
    
    11.2 MTCNN não detecta faces:
    Causa: Qualidade dos vídeos
    Requisito: Rostos visíveis e bem iluminados
    Solução: Ajustar threshold em src/preprocessing.py
    
    11.3 Módulo não encontrado:
    Solução: Reinstalar dependências
    ```bash
    pip install -r requirements.txt --force-reinstall
    ```
    
    11.4 Interface Gradio não abre:
    Causa: Porta 7860 ocupada
    Solução: Especificar porta diferente em src/interface.py
    ```python
    demo.launch(server_port=7861)
    ```

Estatísticas do README.md:
--------------------------

TAMANHO:
- Linhas: 663
- Palavras: ~4500
- Caracteres: ~32 KB

SEÇÕES: 11 principais
- Especificações Técnicas
- Estrutura do Projeto
- Instalação (4 passos)
- Treinamento
- Avaliação (3 subseções)
- Interface Gradio
- Relatórios (2 subseções)
- Arquivos Finais (5 categorias)
- Comandos Úteis (4 subseções)
- Resultados Esperados (3 subseções)
- Troubleshooting (4 problemas)

BLOCOS DE CÓDIGO: 28
- Comandos bash: 18
- Código Python: 7
- Exemplos de output: 3

LISTAS:
- Arquivos finais: 40+ itens
- Dependências: 9 principais
- Degradações: 13 tipos
- Métricas: 15+ tipos

TABELAS: 1
- Métricas Cross-Dataset (3 datasets × 5 métricas)

LINKS/REFERÊNCIAS:
- URLs: 1 (Gradio local)
- Caminhos de arquivo: 60+
- Comandos exatos: 30+

Arquivos Citados no README:
----------------------------

CÓDIGO FONTE (7):
✓ src/preprocessing.py
✓ src/model.py
✓ src/gradcam.py
✓ src/train.py
✓ src/evaluate.py
✓ src/interface.py
✓ src/utils.py

CONFIGURAÇÃO (2):
✓ requirements.txt
✓ instructions.json

MODELO (1):
✓ models/model_best.pt

MÉTRICAS (5):
✓ outputs/metrics_train.csv
✓ outputs/metrics_cross.csv
✓ outputs/reports/table_metrics.csv
✓ outputs/reports/robustness.csv
✓ outputs/reports/interface_log.csv

FIGURAS (13):
✓ outputs/figures/training_curves.png
✓ outputs/figures/f1_by_dataset.png
✓ outputs/figures/gradcam_examples.png
✓ outputs/figures/robustness.png
✓ outputs/figures/confusion_matrix_faceforensics.png
✓ outputs/figures/confusion_matrix_celebdf.png
✓ outputs/figures/confusion_matrix_wilddeepfake.png
✓ outputs/figures/roc_curve_faceforensics.png
✓ outputs/figures/roc_curve_celebdf.png
✓ outputs/figures/roc_curve_wilddeepfake.png
✓ outputs/figures/model_architecture.png
✓ outputs/figures/preprocessing_example.png
✓ outputs/figures/preprocessing_comparison.png

RELATÓRIOS (1):
✓ outputs/reports/run_report.md

LOGS (6):
✓ outputs/logs/early_stopping.txt
✓ outputs/logs/preprocessing_stats.txt
✓ outputs/logs/model_specs.txt
✓ outputs/logs/dataloader_stats.txt
✓ outputs/logs/step_*.txt (1-15)
✓ outputs/logs/README_tasks_7_8.md

DATASETS (3):
✓ data/faceforensicspp_index.csv
✓ data/celebdf_index.csv
✓ data/wilddeepfake_index.csv
✓ data/splits_faceforensicspp.csv

TOTAL: 40+ arquivos citados ✓

Comandos Exatos Fornecidos:
---------------------------

INSTALAÇÃO (6 comandos):
✓ git clone <repository-url>
✓ cd deepfake_detector
✓ pyenv install 3.11.5
✓ pyenv local 3.11.5
✓ python --version
✓ pip install -r requirements.txt

PREPARAÇÃO DADOS (2 comandos):
✓ create_dataset_index() × 3 datasets
✓ create_train_val_test_split()

TREINAMENTO (1 comando):
✓ python src/train.py

AVALIAÇÃO (3 comandos):
✓ python src/evaluate.py
✓ python src/gradcam.py
✓ test_robustness() (automático)

RELATÓRIOS (2 comandos):
✓ generate_technical_report()
✓ generate_all_figures_and_reports()

INTERFACE (1 comando):
✓ python src/interface.py

PIPELINE COMPLETO (7 passos):
✓ Todos os comandos acima em sequência

VERIFICAÇÃO (5 comandos):
✓ ls -lh models/
✓ ls -lh outputs/*/
✓ torch.load('models/model_best.pt')
✓ head -10 outputs/metrics_train.csv
✓ cat outputs/metrics_cross.csv

TOTAL: 27+ comandos exatos ✓

Validação dos Critérios:
------------------------

Conforme instructions.json Task 15:
✓ README.md editado (não criado do zero)
✓ Instruções únicas de instalação
✓ Comandos de treino especificados
✓ Comandos de avaliação especificados
✓ Instruções de uso da interface
✓ Todos os arquivos finais citados
✓ Comandos exatos fornecidos

Conforme acceptance_criteria:
✓ Nenhum arquivo duplicado criado
✓ Caminhos consistentes
✓ Scripts reexecutáveis
✓ Logs sobrescritos (não replicados)
✓ Projeto executável (Python 3.11.5 + PyTorch >= 2.2)

Destaques da Documentação:
---------------------------

1. COMPLETUDE:
   - Cobre todo o pipeline (instalação → interface)
   - 11 seções principais
   - 28 blocos de código
   - 40+ arquivos citados
   - 27+ comandos exatos

2. USABILIDADE:
   - Instruções passo a passo
   - Exemplos de código
   - Outputs esperados
   - Troubleshooting
   - Pipeline completo em 7 comandos

3. DETALHAMENTO:
   - Configurações de treinamento
   - Parâmetros de cada função
   - Estrutura de cada arquivo
   - Métricas esperadas
   - Tempos de execução

4. ORGANIZAÇÃO:
   - Estrutura hierárquica clara
   - Navegação fácil
   - Seções temáticas
   - Comandos agrupados
   - Tabela de resultados

5. PROFISSIONALISMO:
   - Formatação Markdown adequada
   - Emojis para navegação
   - Blocos de código formatados
   - Tabela de métricas
   - Data de atualização

Observações Finais:
-------------------

✓ README.md COMPLETO E PROFISSIONAL
✓ Todas as instruções necessárias incluídas
✓ Comandos exatos e testáveis
✓ Arquivos finais todos citados
✓ Pipeline documentado de ponta a ponta
✓ Troubleshooting incluído
✓ Exemplos de código fornecidos
✓ Resultados esperados especificados

O README.md agora serve como:
- Guia de instalação completo
- Manual de uso detalhado
- Referência de comandos
- Documentação técnica
- Guia de troubleshooting

Próximos Passos:
----------------
✓ PROJETO COMPLETO (15/15 tarefas)
✓ Documentação finalizada
✓ Pronto para uso e distribuição

O projeto Deepfake Detector está COMPLETO e TOTALMENTE DOCUMENTADO!
